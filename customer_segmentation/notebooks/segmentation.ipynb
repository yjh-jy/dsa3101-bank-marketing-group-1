{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af7c648",
   "metadata": {},
   "source": [
    "# Customer Segmentation\n",
    "\n",
    "The goal is to segment customers effectively based on their banking behavior and preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2829b84a",
   "metadata": {},
   "source": [
    "# Preparing the Data\n",
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "d4f4996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54864dfe",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "e0fa2dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/teresaliau/Desktop/y3s2/dsa3101/dsa project/dsa3101-bank-marketing-group-1/customer_segmentation/notebooks\n"
     ]
    }
   ],
   "source": [
    "project_root = os.getcwd()  # Assumes script runs from project root\n",
    "print(project_root)\n",
    "\n",
    "# Define the path to the processed data folder\n",
    "data_path = os.path.join(project_root, \"..\", \"..\", \"data\", \"processed\")\n",
    "\n",
    "# Load the CSV files\n",
    "customer_df = pd.read_csv(os.path.join(data_path, \"customer.csv\"))\n",
    "digital_usage_df = pd.read_csv(os.path.join(data_path, \"digital_usage.csv\"))\n",
    "transactions_df = pd.read_csv(os.path.join(data_path, \"transactions.csv\"))\n",
    "products_df = pd.read_csv(os.path.join(data_path, \"products_owned.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83a11d",
   "metadata": {},
   "source": [
    "## Ensure dates are in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "e32bcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df[\"transaction_date\"] = pd.to_datetime(transactions_df[\"transaction_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e2f0b",
   "metadata": {},
   "source": [
    "## Creating interaction terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59e4a4",
   "metadata": {},
   "source": [
    "### Transaction Table\n",
    "To capture recent customer activity, the script calculates the number of days since each customerâ€™s last transaction from our reference date (2025-01-01). We also computed the average transaction amount per customer. The average is calculated as total amount divided by count, with safeguards in place to handle missing values or potential division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "24ca42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days from last transaction\n",
    "latest_transaction = transactions_df.groupby(\"customer_id\")[\"transaction_date\"].max().reset_index()\n",
    "latest_transaction[\"transaction_date\"] = pd.to_datetime(latest_transaction[\"transaction_date\"]) \n",
    "reference_date = pd.to_datetime(\"2025-01-01\")\n",
    "latest_transaction[\"days_from_last_transaction\"] = (reference_date - latest_transaction[\"transaction_date\"]).dt.days\n",
    "latest_transaction = latest_transaction[[\"customer_id\", \"days_from_last_transaction\"]]\n",
    "### Calculate avg_transaction_amt per customer\n",
    "transaction_summary = transactions_df.groupby(\"customer_id\").agg(total_transaction_amt=(\"transaction_amt\", \"sum\"),num_transactions=(\"transaction_id\", \"count\")).reset_index()\n",
    "transaction_summary[\"avg_transaction_amt\"] = transaction_summary[\"total_transaction_amt\"] / transaction_summary[\"num_transactions\"]\n",
    "transaction_summary[\"avg_transaction_amt\"] = transaction_summary[\"avg_transaction_amt\"].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "transaction_summary = transaction_summary[[\"customer_id\", \"avg_transaction_amt\", \"num_transactions\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab418f0",
   "metadata": {},
   "source": [
    "### Digital Usage table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd8fdc",
   "metadata": {},
   "source": [
    "This code computes a digital engagement score for each customer based on their online activity.\n",
    "    \n",
    "Combine both metrics into a weighted score:\n",
    "\n",
    "- Logins (70%) contribute more since frequent logins indicate active engagement.\n",
    "- Session time (30%) contributes less but still matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "b5e169c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate digital engagement score\n",
    "scaler = StandardScaler()\n",
    "digital_usage_df[\"normalized_logins\"] = scaler.fit_transform(digital_usage_df[[\"mobile_logins_wk\", \"web_logins_wk\"]].sum(axis=1).values.reshape(-1, 1))\n",
    "digital_usage_df[\"normalized_session_time\"] = scaler.fit_transform(digital_usage_df[[\"avg_mobile_time\", \"avg_web_time\"]].sum(axis=1).values.reshape(-1, 1))\n",
    "digital_usage_df[\"digital_engagement_score\"] = (digital_usage_df[\"normalized_logins\"] * 0.7 +digital_usage_df[\"normalized_session_time\"] * 0.3)\n",
    "# Correct aggregation step\n",
    "digital_engagement = digital_usage_df.groupby(\"customer_id\", as_index=False)[\"digital_engagement_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d1e91",
   "metadata": {},
   "source": [
    "### Products table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f8e6a",
   "metadata": {},
   "source": [
    "This code calculates the total number of financial products a customer owns from the bank, which helps measure their relationship with the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "c2f354c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total products owned\n",
    "products_df[\"total_products_owned\"] = products_df.iloc[:, 1:].sum(axis=1)\n",
    "products_summary = products_df[[\"customer_id\", \"total_products_owned\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659e505",
   "metadata": {},
   "source": [
    "### Customer table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9539239",
   "metadata": {},
   "source": [
    "This code selects relevant financial and behavioral attributes from the customer dataset to be used in segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "58ed9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting relevant columns from customer table\n",
    "customer_features = ['customer_id', 'income', 'balance', 'customer_lifetime_value', 'debt', 'tenure', 'default']\n",
    "customer_subset_df = customer_df[customer_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd03be3",
   "metadata": {},
   "source": [
    "## Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "1b6fe0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MERGE DATASETS\n",
    "df = customer_subset_df.merge(latest_transaction, on=\"customer_id\", how=\"left\")\n",
    "df = df.merge(transaction_summary[[\"customer_id\", \"avg_transaction_amt\", \"num_transactions\"]], on=\"customer_id\", how=\"left\")\n",
    "df = df.merge(digital_engagement[[\"customer_id\", \"digital_engagement_score\"]], on=\"customer_id\", how=\"left\")\n",
    "df = df.merge(products_df[[\"customer_id\", \"total_products_owned\"]], on=\"customer_id\", how=\"left\")\n",
    "\n",
    "# Insert another interaction term (transaction freq)\n",
    "# Since data only avail from 2023-2024, transactions before 2023 for those with tenure >24 months not consider\n",
    "df[\"effective_tenure\"] = df[\"tenure\"].clip(upper=24)\n",
    "df[\"transaction_freq\"] = df[\"num_transactions\"] / df[\"effective_tenure\"]\n",
    "df[\"transaction_freq\"] = df[\"transaction_freq\"].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "df.drop(columns=[\"effective_tenure\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "c5af67e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   customer_id                 4000 non-null   int64  \n",
      " 1   income                      4000 non-null   float64\n",
      " 2   balance                     4000 non-null   float64\n",
      " 3   customer_lifetime_value     4000 non-null   float64\n",
      " 4   debt                        4000 non-null   float64\n",
      " 5   tenure                      4000 non-null   int64  \n",
      " 6   default                     4000 non-null   int64  \n",
      " 7   days_from_last_transaction  1853 non-null   float64\n",
      " 8   avg_transaction_amt         1853 non-null   float64\n",
      " 9   num_transactions            1853 non-null   float64\n",
      " 10  digital_engagement_score    3981 non-null   float64\n",
      " 11  total_products_owned        4000 non-null   int64  \n",
      " 12  transaction_freq            4000 non-null   float64\n",
      "dtypes: float64(9), int64(4)\n",
      "memory usage: 406.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "4b97f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id                      0\n",
      "income                           0\n",
      "balance                          0\n",
      "customer_lifetime_value          0\n",
      "debt                             0\n",
      "tenure                           0\n",
      "default                          0\n",
      "days_from_last_transaction    2147\n",
      "avg_transaction_amt           2147\n",
      "num_transactions              2147\n",
      "digital_engagement_score        19\n",
      "total_products_owned             0\n",
      "transaction_freq                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd1a318",
   "metadata": {},
   "source": [
    "## Handling missing values\n",
    "\n",
    "Missing values are handled carefully based on the meaning of each feature:\n",
    "\n",
    "1. `Digital engagement score``: Only 19 customers had missing values, so we impute using the mean to preserve overall engagement trends.\n",
    "\n",
    "2. `Transaction-related features``:  \n",
    "   - If a customer has no transaction records, we assume:\n",
    "     - `avg_transaction_amt` = 0 (no spending)\n",
    "     - `num_transactions` = 0 (no activity)\n",
    "     - `transaction_freq` = 0 (no frequency)\n",
    "   - For `days_from_last_transaction`, we assign a high but reasonable value â€” the current max value plus a 30-day buffer â€” to reflect inactivity without skewing the scale too far.\n",
    "\n",
    "This targeted approach ensures that missing data is handled logically while minimizing distortion of actual customer behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "c46d8514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/5cwlt66x6d12kf_tz4qkd_580000gn/T/ipykernel_42667/3874435748.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"digital_engagement_score\"].fillna(df[\"digital_engagement_score\"].mean(), inplace=True)\n",
      "/var/folders/wc/5cwlt66x6d12kf_tz4qkd_580000gn/T/ipykernel_42667/3874435748.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"avg_transaction_amt\"].fillna(0, inplace=True)\n",
      "/var/folders/wc/5cwlt66x6d12kf_tz4qkd_580000gn/T/ipykernel_42667/3874435748.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"transaction_freq\"].fillna(0, inplace=True)\n",
      "/var/folders/wc/5cwlt66x6d12kf_tz4qkd_580000gn/T/ipykernel_42667/3874435748.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"num_transactions\"].fillna(0, inplace=True)\n",
      "/var/folders/wc/5cwlt66x6d12kf_tz4qkd_580000gn/T/ipykernel_42667/3874435748.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"days_from_last_transaction\"].fillna(df[\"days_from_last_transaction\"].max() + 30, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## HANDLING MISSING VALUES\n",
    "### engagement score only has 19 missing values -> fill with mean\n",
    "df[\"digital_engagement_score\"].fillna(df[\"digital_engagement_score\"].mean(), inplace=True)\n",
    "### no transaction record (we set transactions to be 0)\n",
    "df[\"avg_transaction_amt\"].fillna(0, inplace=True)\n",
    "df[\"transaction_freq\"].fillna(0, inplace=True)\n",
    "df[\"num_transactions\"].fillna(0, inplace=True)\n",
    "### some did not do transactions. we set the days from last transaction to be a high but not too extreme value. We add a month of buffer\n",
    "df[\"days_from_last_transaction\"].fillna(df[\"days_from_last_transaction\"].max() + 30, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "c5416dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id                   0\n",
      "income                        0\n",
      "balance                       0\n",
      "customer_lifetime_value       0\n",
      "debt                          0\n",
      "tenure                        0\n",
      "default                       0\n",
      "days_from_last_transaction    0\n",
      "avg_transaction_amt           0\n",
      "num_transactions              0\n",
      "digital_engagement_score      0\n",
      "total_products_owned          0\n",
      "transaction_freq              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343eb69",
   "metadata": {},
   "source": [
    "# Check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "37c0fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = [ \"income\", \"balance\", \"debt\", \"customer_lifetime_value\",\"days_from_last_transaction\", \"avg_transaction_amt\",\"digital_engagement_score\", \"total_products_owned\", \"transaction_freq\"]\n",
    "# Check for outliers\n",
    "# Create 3x3 grid\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))\n",
    "fig.suptitle(\"Feature-Wise Outlier Visualization\", fontsize=16)\n",
    "axes = axes.flatten()\n",
    "\n",
    "visuals_path = os.path.join(project_root,\"..\", \"visuals\")\n",
    "os.makedirs(visuals_path, exist_ok=True)\n",
    "# Plot boxplots\n",
    "for i, feature in enumerate(features_to_scale):\n",
    "    sns.boxplot(y=df[feature], ax=axes[i])\n",
    "    axes[i].set_title(feature)\n",
    "    axes[i].set_ylabel(\"\")  # optional: remove y-axis label for cleaner look\n",
    "    axes[i].grid(True)\n",
    "# Adjust layout to make space for title\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plot_path = os.path.join(visuals_path, \"boxplots.png\")\n",
    "plt.savefig(plot_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "03c62fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Outlier Count\n",
      "customer_id                             0\n",
      "income                                 60\n",
      "balance                                38\n",
      "customer_lifetime_value                55\n",
      "debt                                   89\n",
      "tenure                                 16\n",
      "default                                 0\n",
      "days_from_last_transaction              0\n",
      "avg_transaction_amt                    83\n",
      "num_transactions                       68\n",
      "digital_engagement_score                0\n",
      "total_products_owned                   30\n",
      "transaction_freq                       76\n"
     ]
    }
   ],
   "source": [
    "# Define function to count outliers using Z-score method\n",
    "def count_outliers_zscore(df, threshold=3):\n",
    "    outlier_counts = {}\n",
    "\n",
    "    for col in df.select_dtypes(include=[np.number]): \n",
    "        z_scores = np.abs(zscore(df[col])) \n",
    "        num_outliers = (z_scores > threshold).sum()\n",
    "        outlier_counts[col] = num_outliers\n",
    "\n",
    "    return pd.DataFrame.from_dict(outlier_counts, orient=\"index\", columns=[\"Outlier Count\"])\n",
    "\n",
    "\n",
    "# Apply to dataset\n",
    "outliers_zscore_df = count_outliers_zscore(df)\n",
    "print(outliers_zscore_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c685e77",
   "metadata": {},
   "source": [
    "# Standardizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169bd1b",
   "metadata": {},
   "source": [
    "To prepare features for clustering, we first applied **winsorization** to cap extreme outliers. \n",
    "\n",
    "- Features like `customer_lifetime_value`, `avg_transaction_amt`, and `transaction_freq` were lest skewed, so we applied **1% winsorization** (limits = `[0.0, 0.01]`).\n",
    "- Wealth-related features like `income`, `balance`, and `debt` were more skewed, so we applied a stronger **10% winsorization** to reduce the influence of extreme values (limits = `[0.05, 0.10]`).\n",
    "\n",
    "After capping outliers, we applied two types of scaling:\n",
    "\n",
    "1. **RobustScaler** for `robust_features`  \n",
    "   This scaler centers the median at 0 and scales based on the interquartile range (IQR), making it less sensitive to outliers than StandardScaler. It's ideal for features with residual skew even after winsorization.\n",
    "\n",
    "2. **StandardScaler** for `standard_features`  \n",
    "   This scales data to have a mean of 0 and a standard deviation of 1. It's used on features like `days_from_last_transaction`, `digital_engagement_score`, and `total_products_owned`, which are more normally distributed and less impacted by outliers.\n",
    "\n",
    "This preprocessing ensures fair feature contribution to the clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "cb3acd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STANDARDIZING FOR K-MEANS CLUSTERING\n",
    "# Features that need Robust scaling \n",
    "robust_features = [\"income\", \"balance\", \"debt\", \"customer_lifetime_value\",  \"avg_transaction_amt\", \"transaction_freq\"]\n",
    "\n",
    "# Heavily skewed â†’ higher winsorization\n",
    "heavy_outliers = [\"income\", \"balance\", \"debt\"]\n",
    "for col in heavy_outliers:\n",
    "    df[col] = pd.Series(winsorize(df[col].to_numpy(), limits=[0.05, 0.10])).astype(float)\n",
    "\n",
    "# Moderate outliers â†’ light winsorization\n",
    "moderate_outliers = [\"customer_lifetime_value\", \"avg_transaction_amt\", \"transaction_freq\"]\n",
    "for col in moderate_outliers:\n",
    "    df[col] = pd.Series(winsorize(df[col].to_numpy(), limits=[0.0, 0.01])).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# Features that need Standard scaling (normally distributed)\n",
    "standard_features = [\"days_from_last_transaction\", \"digital_engagement_score\", \"total_products_owned\"]\n",
    "\n",
    "# Apply RobustScaler\n",
    "scalerrobust =  RobustScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[robust_features] = scalerrobust.fit_transform(df[robust_features])\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "df_scaled[standard_features] = scaler_standard.fit_transform(df[standard_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13297d",
   "metadata": {},
   "source": [
    "# PCA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9672b",
   "metadata": {},
   "source": [
    "This code performs Principal Component Analysis (PCA) to analyze how much variance each feature contributes to the dataset. explained_variance_ratio_: Measures how much variance each principal component captures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "4e5bf1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA Explained Variance:\n",
      "                             Explained Variance\n",
      "income                                0.330845\n",
      "balance                               0.201121\n",
      "debt                                  0.132863\n",
      "customer_lifetime_value               0.127235\n",
      "days_from_last_transaction            0.079680\n",
      "avg_transaction_amt                   0.063213\n",
      "digital_engagement_score              0.036197\n",
      "total_products_owned                  0.024265\n",
      "transaction_freq                      0.004581\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=len(features_to_scale))  # Keep all components\n",
    "df_pca = pca.fit_transform(df_scaled[features_to_scale])\n",
    "\n",
    "# Convert to DataFrame\n",
    "explained_variance = pd.DataFrame(\n",
    "    pca.explained_variance_ratio_,\n",
    "    index=features_to_scale,\n",
    "    columns=[\"Explained Variance\"]\n",
    ")\n",
    "\n",
    "# Print explained variance of each feature\n",
    "print(\"\\nPCA Explained Variance:\\n\", explained_variance.sort_values(by=\"Explained Variance\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "1fe05303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['customer_id', 'income', 'balance', 'customer_lifetime_value', 'debt',\n",
      "       'tenure', 'default', 'days_from_last_transaction',\n",
      "       'avg_transaction_amt', 'num_transactions', 'digital_engagement_score',\n",
      "       'total_products_owned', 'transaction_freq'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "features = df.columns\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd391db",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c494d",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "We use k = 3 to segment the customers into 3 categories \n",
    "1. High value\n",
    "2. Budget conscious\n",
    "3. At risk / inactive customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "0e9e1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-MEANS CLUSTERING\n",
    "optimal_k = 3\n",
    "df_scaled[\"Cluster\"] = KMeans(n_clusters= optimal_k,  init=\"k-means++\", n_init=20, random_state=42).fit_predict(df_scaled[features_to_scale])\n",
    "df[\"Cluster\"] = df_scaled[\"Cluster\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3577e3",
   "metadata": {},
   "source": [
    "### Number of clients in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "a9f72500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    2287\n",
      "2    1297\n",
      "0     416\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Cluster\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b51f4",
   "metadata": {},
   "source": [
    "# Evaluation: Silhouette Score\n",
    " This score shows how similar an object is to its own cluster (cohesion) compared to other clusters (separation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "ba2ca563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score = 0.2336\n"
     ]
    }
   ],
   "source": [
    "# Silhouette Score\n",
    "silhouette_avg = silhouette_score(df_scaled[features_to_scale], df[\"Cluster\"])\n",
    "print(f\"Silhouette Score = {silhouette_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f31304",
   "metadata": {},
   "source": [
    "Silhouette Score = 0.2336, indicating that while the segments have meaningful distinctions, there is moderate overlap between customer groups. Customer data typically includes heterogeneous characteristics (e.g., behavioral, transactional, demographic attributes) that naturally reduce clear separations between segments. The segments are designed based on business logic (engagement, spending, product usage),even if silhouette metrics aren't exceptionally high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a25e44",
   "metadata": {},
   "source": [
    "### Getting information about each cluster's mean of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "f53fb1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           income   balance      debt  customer_lifetime_value  \\\n",
      "Cluster                                                          \n",
      "0        1.096870  2.152045  0.281576                 0.548329   \n",
      "1        0.121799  0.461907  0.199057                 0.100251   \n",
      "2       -0.167243 -0.035334  0.168231                 0.067268   \n",
      "\n",
      "         days_from_last_transaction  avg_transaction_amt  \\\n",
      "Cluster                                                    \n",
      "0                         -1.158732             2.770479   \n",
      "1                          0.800823             0.039179   \n",
      "2                         -1.040439             0.985565   \n",
      "\n",
      "         digital_engagement_score  total_products_owned  transaction_freq  \n",
      "Cluster                                                                    \n",
      "0                        0.027024              0.126785          2.050743  \n",
      "1                       -0.004964             -0.030528          0.033603  \n",
      "2                        0.000086              0.013166          1.393783  \n"
     ]
    }
   ],
   "source": [
    "cluster_means = df_scaled.groupby(\"Cluster\")[features_to_scale].mean()\n",
    "print(cluster_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b491a6b",
   "metadata": {},
   "source": [
    "## Cluster Labels\n",
    "We assign higher weights for critical factors that define customer value:\n",
    "- income (10%) â†’ High value customers likely to be more financially healthy\n",
    "- balance (10%) â†’ Same reason as above\n",
    "- customer_lifetime_value (15%) â†’ Long-term revenue predictor.\n",
    "- avg_transaction_amt (20%) â†’ High-value customers spend more per transaction.\n",
    "- digital_engagement_score (20%) â†’ Engaged customers are more valuable.\n",
    "- total_products_owned (20%) â†’ Owning multiple products strengthens customer loyalty.\n",
    "- transaction_freq (20%) â†’ Frequent transactions signal active customers.\n",
    "\n",
    "\n",
    "\n",
    "Penalty for inactivity:\n",
    "- days_from_last_transaction (- 20%) â†’ Longer inactivity lowers score.\n",
    "Slight penalty for financial distress:\n",
    "- debt (-5%) â†’ High debt can indicate financial risk.\n",
    "\n",
    "We assign segments dynamically based on rankings\n",
    "- Top cluster = High-Value\n",
    "- 2rd highest = Budget-Conscious\n",
    "- Last = Inactive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "fd60f01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Ranking by Score (Best to Worst):\n",
      "Rank 1: Cluster 0 â†’ High-value\n",
      "Rank 2: Cluster 2 â†’ Budget-conscious\n",
      "Rank 3: Cluster 1 â†’ At risk / inactive customers\n"
     ]
    }
   ],
   "source": [
    "cluster_means[\"score\"] = (\n",
    "    cluster_means[\"income\"] * 0.1 + \n",
    "    cluster_means[\"balance\"] * 0.1 + \n",
    "    cluster_means[\"debt\"] * (-0.05) +  # Negative weight for financial distress\n",
    "    cluster_means[\"customer_lifetime_value\"] * 0.15 +  # Increased because CLV predicts revenue\n",
    "    cluster_means[\"days_from_last_transaction\"] * (-0.20) +  # Increased penalty for inactivity\n",
    "    cluster_means[\"avg_transaction_amt\"] * 0.20 +  # High-value customers spend more per transaction\n",
    "    cluster_means[\"digital_engagement_score\"] * 0.20 +  # More engagement means higher retention\n",
    "    cluster_means[\"total_products_owned\"] * 0.20 +  # Owning more products = stronger banking relationship\n",
    "    cluster_means[\"transaction_freq\"] * 0.20  # Higher impact because frequent usage matters\n",
    ")\n",
    "\n",
    "\n",
    "# Rank Clusters Based on Score (Descending)\n",
    "sorted_clusters = cluster_means[\"score\"].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "# Assign Segments Based on Rank\n",
    "dynamic_segment_mapping = {\n",
    "    sorted_clusters[0]: \"High-value\",\n",
    "    sorted_clusters[1]: \"Budget-conscious\",\n",
    "    sorted_clusters[2]: \"At risk / inactive customers\"\n",
    "}\n",
    "\n",
    "# Print cluster rankings before applying\n",
    "print(\"\\nCluster Ranking by Score (Best to Worst):\")\n",
    "for i, cluster in enumerate(sorted_clusters):\n",
    "    print(f\"Rank {i+1}: Cluster {cluster} â†’ {dynamic_segment_mapping[cluster]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86caa4",
   "metadata": {},
   "source": [
    "# Creating DF with the segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "c3ad3194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment\n",
      "At risk / inactive customers    2287\n",
      "Budget-conscious                1297\n",
      "High-value                       416\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply Mapping to DataFrame\n",
    "df[\"Segment\"] = df[\"Cluster\"].map(dynamic_segment_mapping)\n",
    "print(df[\"Segment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "8eeb2511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id                       Segment\n",
      "0          449  At risk / inactive customers\n",
      "1          309  At risk / inactive customers\n",
      "2           78  At risk / inactive customers\n",
      "3          258              Budget-conscious\n",
      "4          151              Budget-conscious\n"
     ]
    }
   ],
   "source": [
    "df_final = df[[\"customer_id\", \"Segment\"]]\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "9de701eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of original features per segment:\n",
      "                                   income      balance          debt  \\\n",
      "Segment                                                                \n",
      "At risk / inactive customers  4638.945138   938.703629  23223.279134   \n",
      "Budget-conscious              3617.939314   309.687664  22556.080100   \n",
      "High-value                    8083.261731  3076.748894  25009.298894   \n",
      "\n",
      "                              customer_lifetime_value  \\\n",
      "Segment                                                 \n",
      "At risk / inactive customers               330.465982   \n",
      "Budget-conscious                           324.298443   \n",
      "High-value                                 414.252019   \n",
      "\n",
      "                              days_from_last_transaction  avg_transaction_amt  \\\n",
      "Segment                                                                         \n",
      "At risk / inactive customers                  749.586795            10.821415   \n",
      "Budget-conscious                              214.720894           272.219962   \n",
      "High-value                                    180.358173           765.225356   \n",
      "\n",
      "                              digital_engagement_score  total_products_owned  \\\n",
      "Segment                                                                        \n",
      "At risk / inactive customers                 -0.004569              1.756012   \n",
      "Budget-conscious                             -0.000371              1.801079   \n",
      "High-value                                    0.022025              1.918269   \n",
      "\n",
      "                              transaction_freq  \n",
      "Segment                                         \n",
      "At risk / inactive customers          0.002800  \n",
      "Budget-conscious                      0.116149  \n",
      "High-value                            0.170895  \n"
     ]
    }
   ],
   "source": [
    "# Getting information of these segments\n",
    "segment_means = df.groupby(\"Segment\")[features_to_scale].mean()\n",
    "# Display the results\n",
    "print(\"Mean of original features per segment:\")\n",
    "print(segment_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0c7c1",
   "metadata": {},
   "source": [
    "## Creates csv table in under customer segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "8b7705e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/teresaliau/Desktop/y3s2/dsa3101/dsa project/dsa3101-bank-marketing-group-1/customer_segmentation/notebooks\n"
     ]
    }
   ],
   "source": [
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "b727d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'customer_segments.csv' with Customer ID & segment name\n"
     ]
    }
   ],
   "source": [
    "## Creates csv table in under customer segmentation\n",
    "df_final.to_csv(os.path.join(project_root, \"..\" , \"customer_segments.csv\"), index=False)\n",
    "print(\"Saved 'customer_segments.csv' with Customer ID & segment name\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
